{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "later-compression",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "[1 Importing packages](#1)<br>\n",
    "[2 Read CSV train/test files into DataFrame](#2)<br>\n",
    "[3 Data Preprocessing](#3)<br>\n",
    "    <ul>\n",
    "        <li>[3.1 Missing Values](#31)</li>\n",
    "        <li>[3.2 Drop Features Using Pearson Correlation](#32)</li>\n",
    "    </ul>\n",
    "[4 Regressions and Results](#4)<br>\n",
    "    <ul>\n",
    "        <li>[4.1 Separate the dataset into train and test](#41)</li>\n",
    "        <li>[4.2 Check categorical columns](#42)</li>\n",
    "        <li>[4.3 Check zero variance features](#43)</li>\n",
    "        <li>[4.4 Feature Selection](#44)</li>\n",
    "        <li>[4.5 Running Machine Learning Models](#45)</li>\n",
    "        <li>[4.6 Evaluating the Model ](#46)</li>\n",
    "    </ul>\n",
    "[5. Submission](#5)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-system",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h2>1 Importing packages</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import math, time, datetime\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "# display all of the columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# from scipy import stats\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-plumbing",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "   <h2>\n",
    "    2 Read CSV train/test files into DataFrame\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"datasets/train.csv\")\n",
    "test = pd.read_csv(\"datasets/test.csv\")\n",
    "gender_submission = pd.read_csv(\"datasets/gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependent variable\n",
    "y = train['Survived']\n",
    "# independent variables\n",
    "train = train.drop('Survived', axis=1)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-while",
   "metadata": {},
   "source": [
    "pclass: A proxy for socio-economic status (SES)<br>\n",
    "1st = Upper<br>\n",
    "2nd = Middle<br>\n",
    "3rd = Lower<br>\n",
    "<br>\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5<br>\n",
    "sibsp: The dataset defines family relations in this way...<br>\n",
    "Sibling = brother, sister, stepbrother, stepsister<br>\n",
    "Spouse = husband, wife (mistresses and fianc√©s were ignored)<br>\n",
    "parch: The dataset defines family relations in this way...<br>\n",
    "Parent = mother, father<br>\n",
    "Child = daughter, son, stepdaughter, stepson<br>\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 2))\n",
    "# Horizontal bar chart\n",
    "ax.barh(y.unique(), y.value_counts(), align='center', color=['red', 'green'])\n",
    "ax.text(530, 0, y.value_counts()[0], ha='center', va='center', color='w', size=20)\n",
    "ax.text(320, 1, y.value_counts()[1], ha='center', va='center', color='w', size=20)\n",
    "ax.set_yticks(y.unique())\n",
    "ax.set_yticklabels(y.unique())\n",
    "ax.invert_yaxis()\n",
    "ax.set_ylabel('Survived')\n",
    "ax.set_title('How many people survived?')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test]).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-property",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "   <h2>\n",
    "    3 Data Preprocessing\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-cleveland",
   "metadata": {},
   "source": [
    "<a id='31'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        3.1 Extract titles from the 'Name' column\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-electric",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "title = []\n",
    "for i in df['Name']:\n",
    "    title.append(re.search('([A-Z][a-z]+)\\.',i)[1])\n",
    "\n",
    "# create a column named 'Title'\n",
    "df[\"Title\"] = title\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Title'] == 'Master']['Sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = df['Title'].value_counts()\n",
    "title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-formation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "male_list = []\n",
    "female_list = []\n",
    "unknown_list = []\n",
    "for ind in title_list.index:\n",
    "    if not ind in ['Mr', 'Miss', 'Mrs']:\n",
    "        # get the gender from the 'Sex' column\n",
    "        title_uni = df[df['Title'] == ind]['Sex'].unique()\n",
    "        # ['male'] or ['female']\n",
    "        if len(title_uni) == 1:\n",
    "            if title_uni[0] == 'male':\n",
    "                male_list.append(ind)\n",
    "            else:\n",
    "                female_list.append(ind)\n",
    "        # ['male' 'female']\n",
    "        else:\n",
    "            unknown_list.append(ind)\n",
    "print('male_list ->', male_list)\n",
    "print('female_list ->',female_list)\n",
    "print('unknown_list ->',unknown_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace male_list's items in the 'Title' column with 'Mr'\n",
    "for male in male_list:\n",
    "    df['Title']=df['Title'].replace([male],'Mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataframe using the female_list to get the age distribution.\n",
    "# thus, each item will be determined whether the female person is 'Miss' or 'Mrs'.\n",
    "filt = ((df['Title'] == 'Ms') | (df['Title'] == 'Mlle') | (df['Title'] == 'Lady') | \n",
    "        (df['Title'] == 'Dona') | (df['Title'] == 'Mme') | (df['Title'] == 'Countess'))\n",
    "\n",
    "df[filt][['Title', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine if the female person is 'Miss' or 'Mrs'.\n",
    "df['Title']=df['Title'].replace(['Mme', 'Ms', 'Mlle'],'Miss')\n",
    "df['Title']=df['Title'].replace(['Lady', 'Countess', 'Dona'],'Mrs')\n",
    "\n",
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataframe using the unknown_list to get the age and sex distribution.\n",
    "filt = (df['Title'] == 'Dr')\n",
    "df[filt][['Title', 'Sex', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the title in the index 796 as 'Mrs' and the others as 'Mr'\n",
    "df.loc[796, 'Title'] = 'Mrs'\n",
    "df['Title']=df['Title'].replace(['Dr'],'Mr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop unnecessary columns, which won't be used in analysis and prediction\n",
    "# df = df.drop(['Name', 'Sex', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_type = []\n",
    "ticket_num_len = []\n",
    "for i in df['Ticket']:\n",
    "    splitted = i.split(' ')\n",
    "    if len(splitted)==1:\n",
    "        ticket_type.append('no_type')\n",
    "        ticket_num_len.append(len(splitted[0].strip()))\n",
    "    elif len(splitted)==2:\n",
    "        ticket_type.append(splitted[0].strip())\n",
    "        ticket_num_len.append(len(splitted[1]))\n",
    "    elif len(splitted)==3:\n",
    "        ticket_type.append((''.join(splitted[0:2]).strip()))\n",
    "        ticket_num_len.append(len(splitted[2].strip()))\n",
    "    else:\n",
    "        print(i)\n",
    "\n",
    "df['Ticket_type'] = ticket_type\n",
    "df['Ticket_num_len'] = ticket_num_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    if df[col].dtypes == 'object':\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-japanese",
   "metadata": {},
   "source": [
    "<a id='31'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        3.1 Encode categorical columns\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns with value between 0 and the number of items-1\n",
    "cols_encoded = {}\n",
    "\n",
    "columns_info = []\n",
    "for col in df:\n",
    "    each_col_info = []\n",
    "    \n",
    "    # number of unique values\n",
    "    unique_vals = df[col].value_counts(dropna=True).index.to_list()\n",
    "    nr_values = len(unique_vals)\n",
    "    \n",
    "    if df[col].dtypes == 'object':\n",
    "        print(col)\n",
    "        if nr_values < 100:\n",
    "            cols_encoded[col] = []\n",
    "            # get the unique_value and count from iterable list object in the for loop\n",
    "            for i, j in enumerate(unique_vals):\n",
    "                # add each unique value and count to the dictionary\n",
    "                cols_encoded[col].append({i:j})\n",
    "                # replace each unique value with the count to encode \n",
    "                df[col].replace(j, str(i), inplace=True)\n",
    "\n",
    "    # add each column's name, Number of uniques, and Uniques to the each_col_info list\n",
    "    each_col_info.append(col)\n",
    "    each_col_info.append(nr_values)\n",
    "    each_col_info.append(unique_vals)\n",
    "    \n",
    "    # add the list with each column info to the columns_info list\n",
    "    columns_info.append(each_col_info)\n",
    "\n",
    "# create a dataframe using the columns_info list and sort it by 'Number of uniques' column\n",
    "df_values_number = pd.DataFrame(columns_info, columns=['Feature', 'Number of uniques', 'Uniques'])\n",
    "df_values_number.sort_values(by='Number of uniques', inplace=True)\n",
    "df_values_number.reset_index(drop=True, inplace=True)\n",
    "df_values_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-accent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-intellectual",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-george",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-netscape",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticket_type = []\n",
    "# ticket_num_len = []\n",
    "# for i in df['Ticket']:\n",
    "#     splitted = i.split(' ')\n",
    "#     if len(splitted)==1:\n",
    "#         ticket_type.append('no_type')\n",
    "#         ticket_num_len.append(len(splitted[0].strip()))\n",
    "#     elif len(splitted)==2:\n",
    "#         ticket_type.append(splitted[0].strip())\n",
    "#         ticket_num_len.append(len(splitted[1]))\n",
    "#     elif len(splitted)==3:\n",
    "#         ticket_type.append((''.join(splitted[0:2]).strip()))\n",
    "#         ticket_num_len.append(len(splitted[2].strip()))\n",
    "#     else:\n",
    "#         print(i)\n",
    "\n",
    "# df['Ticket_type'] = ticket_type\n",
    "# df['Ticket_num_len'] = ticket_num_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Ticket_num_len'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer\n",
    "\n",
    "# iterative_imputer = IterativeImputer()\n",
    "# df['Age'] = iterative_imputer.fit_transform(df['Age'].values.reshape(-1,1))\n",
    "# df['Age'] = df['Age'].astype('int64')\n",
    "\n",
    "# df['Fare'] = iterative_imputer.fit_transform(df['Fare'].values.reshape(-1,1))\n",
    "# df['Fare'] = df['Fare'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-saskatchewan",
   "metadata": {},
   "source": [
    "<a id='32'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        3.2 Missing Values\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(data=df.isnull(),cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_values = pd.DataFrame(df.isnull().sum().sort_values(ascending=False))\n",
    "nan_values = nan_values[nan_values.iloc[:,0]>0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16, 6))\n",
    "cmap = plt.get_cmap(\"RdBu\")\n",
    "ax.bar(nan_values.index, nan_values.iloc[:,0], color=cmap(nan_values.iloc[:,0]))\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "# from sklearn import utils\n",
    "\n",
    "# def predict_nan(df, dependent_col, selected_col, *argv):\n",
    "#     # create a dataframe without nan values. This df will be used as X_train and y_train\n",
    "#     df_notnan = df.dropna(how='any')\n",
    "    \n",
    "#     # create a dataframe with nan values using the dependent feature\n",
    "#     # This df will be used as X_test.\n",
    "#     df_dep_nan = df[df[dependent_col].isna()]\n",
    "#     # remove the nan values in the other features (Note: argv and (selected_col,) are tuples)\n",
    "#     df_dep_nan.dropna(subset=argv + (selected_col,), how='any', inplace=True)\n",
    "\n",
    "#     # The first 10000 rows will be evaluated as X_train and y_train\n",
    "#     X_train = df_notnan.drop([dependent_col], axis=1).iloc[:10000, :]\n",
    "#     y_train = df_notnan[dependent_col][:10000]\n",
    "    \n",
    "#     # Since the dependent feature will be predicted, drop it from the dataframe\n",
    "#     X_test = df_dep_nan.drop([dependent_col], axis=1)\n",
    "    \n",
    "#     # check the label type to identify the model for prediction\n",
    "#     label_type = utils.multiclass.type_of_target(y_train)\n",
    "#     print(label_type)\n",
    "#     if label_type == 'continuous':\n",
    "#         model = RandomForestRegressor()\n",
    "#     elif label_type == 'multiclass':\n",
    "#         model = RandomForestClassifier()\n",
    "#     model.fit(X_train, y_train.astype('int'))\n",
    "#     generatedValues = model.predict(X_test)\n",
    "    \n",
    "#     # return the index numbers of rows with nan and predicted values\n",
    "#     ind = df_dep_nan.index\n",
    "\n",
    "#     return ind, generatedValues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-empty",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        3.1.1 Fare\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "iterative_imputer = IterativeImputer()\n",
    "df['Fare'] = iterative_imputer.fit_transform(df['Fare'].values.reshape(-1,1))\n",
    "df['Fare'] = df['Fare'].astype('int64')\n",
    "\n",
    "# df['Fare'] = iterative_imputer.fit_transform(df['Fare'].values.reshape(-1,1))\n",
    "# df['Fare'] = df['Fare'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the nan values in the 'Fare' column will be predicted \n",
    "# ind, generatedValues = predict_nan(df, dependent_col='Fare', selected_col='Age')\n",
    "# df.loc[ind,'Fare'] = generatedValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-retrieval",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        3.1.3 Embarked\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "iterative_imputer = IterativeImputer()\n",
    "df['Embarked'] = iterative_imputer.fit_transform(df['Embarked'].values.reshape(-1,1))\n",
    "df['Embarked'] = df['Embarked'].astype('int64')\n",
    "\n",
    "# df['Fare'] = iterative_imputer.fit_transform(df['Fare'].values.reshape(-1,1))\n",
    "# df['Fare'] = df['Fare'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the nan values in the 'Fare' column will be predicted \n",
    "# ind, generatedValues = predict_nan(df, dependent_col='Embarked', selected_col='Age')\n",
    "# df.loc[ind,'Embarked'] = generatedValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-crime",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        3.1.2 Age\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "iterative_imputer = IterativeImputer()\n",
    "df['Age'] = iterative_imputer.fit_transform(df['Age'].values.reshape(-1,1))\n",
    "df['Age'] = df['Age'].astype('int64')\n",
    "\n",
    "# df['Fare'] = iterative_imputer.fit_transform(df['Fare'].values.reshape(-1,1))\n",
    "# df['Fare'] = df['Fare'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the nan values in the 'Fare' column will be predicted \n",
    "# ind, generatedValues = predict_nan(df, dependent_col='Age', selected_col='Fare')\n",
    "# df.loc[ind,'Age'] = np.round(generatedValues, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-alaska",
   "metadata": {},
   "source": [
    "<a id='41'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        4.1 Drop Outliers\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot(df, label):\n",
    "    fig, ax = plt.subplots(figsize = (10, 1))\n",
    "    # rectangular box plot\n",
    "    bplot = ax.boxplot(df,\n",
    "                           vert=False,  # vertical box alignment\n",
    "                           notch=True,  # notch shape\n",
    "                           patch_artist=True,  # fill with color\n",
    "                           labels=[label]  # will be used to label x-ticks\n",
    "                          )\n",
    "    # fill with colors\n",
    "    colors = ['pink', 'lightblue', 'lightgreen']\n",
    "    for box in (bplot):\n",
    "        for patch, color in zip(bplot['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "\n",
    "\n",
    "    whiskers_1 = bplot['whiskers'][0].get_xdata()[1]\n",
    "    whiskers_2 = bplot['whiskers'][0].get_xdata()[0]\n",
    "    median = bplot['medians'][0].get_xdata()[0]\n",
    "    whiskers_3 = bplot['whiskers'][1].get_xdata()[0]\n",
    "    whiskers_4 = bplot['whiskers'][1].get_xdata()[1]\n",
    "    \n",
    "    ax.text(whiskers_1, 1.15, f\"{whiskers_1}\", ha='center', va='center', color='b', size=13)\n",
    "    ax.text(whiskers_2, 1.25, f\"{whiskers_2}\", ha='center', va='center', color='b', size=13)\n",
    "    ax.text(median, 0.7, f\"{median}\", ha='center', va='center', color='b', size=13)\n",
    "    ax.text(whiskers_3, 1.25, f\"{whiskers_3}\", ha='center', va='center', color='b', size=13)\n",
    "    ax.text(whiskers_4, 1.15, f\"{whiskers_4}\", ha='center', va='center', color='b', size=13)\n",
    "\n",
    "\n",
    "    ax.xaxis.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    outliers = bplot['fliers'][0].get_xdata()\n",
    "#     print(sorted(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-effectiveness",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        Age\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Age'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(df['Age'], 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_index_age = df[df['Age'] > 76].index\n",
    "print(outliers_index_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_index_age = df[df['Age'] > 76].index\n",
    "df = df.drop(outliers_index_age, axis=0)\n",
    "y = y.drop(outliers_index_age, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-vancouver",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        Fare\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Fare'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-death",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(df['Fare'], 'Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste bos\n",
    "outliers_index_age = df[df['Fare'] > test['Fare'].max()].index\n",
    "print(outliers_index_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-telling",
   "metadata": {},
   "source": [
    "<a id='32'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        3.2 Categorize Features\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_graph(df, num_bins):\n",
    "    # create a figure and a grid of subplots\n",
    "#     fig, axes = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    sigma = df.dropna().std()\n",
    "    mu = df.dropna().mean()\n",
    "    x = mu + sigma * np.random.randn(1000)\n",
    "    n, bins, patches = plt.hist(df, num_bins, density=True, color='green', \n",
    "                                           stacked=True, alpha=0.75)\n",
    "    y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "        np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "    plt.plot(bins, y, '--', color ='black')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-november",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        3.1.2 Age\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_graph(df['Age'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the \"Age\" column in categorical Bins.\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "k_bins_discretizer = KBinsDiscretizer(n_bins = 10, encode = 'ordinal', strategy = 'quantile')\n",
    "df['Age_discretized'] = k_bins_discretizer.fit_transform(df['Age'].values.reshape(-1,1))\n",
    "df['Age_discretized'] = df['Age_discretized'].astype('int64')\n",
    "df.drop('Age', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-pharmacology",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        3.1.1 Fare\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_graph(df['Fare'], 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the \"Age\" column in categorical Bins.\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "k_bins_discretizer = KBinsDiscretizer(n_bins = 10, encode = 'ordinal', strategy = 'quantile')\n",
    "df['Fare_discretized'] = k_bins_discretizer.fit_transform(df['Fare'].values.reshape(-1,1))\n",
    "df['Fare_discretized'] = df['Fare_discretized'].astype('int64')\n",
    "df.drop('Fare', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-quantum",
   "metadata": {},
   "source": [
    "<a id='31'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        3.1 Investigate all the elements within each Feature\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    if df[col].dtypes == 'object':\n",
    "        df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a matrix of scatter plots to understand the correlation among the features\n",
    "axes = pd.plotting.scatter_matrix(df, alpha=0.7, figsize=(14, 10), diagonal='kde')\n",
    "for ax in axes.flatten():\n",
    "    ax.xaxis.label.set_rotation(0)\n",
    "    ax.yaxis.label.set_rotation(0)\n",
    "    ax.yaxis.label.set_ha('right')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "plt.gcf().subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_graph(df, bar=None, hist=None, scatter=None):\n",
    "    # the number of features that will be used to create a subplot\n",
    "    num_cols = len(bar + hist + scatter)\n",
    "    cols = 0\n",
    "    rows = 0\n",
    "    \n",
    "    # Number of rows/columns of the subplot grid. The max number of columns will be 3.\n",
    "    if num_cols < 4:\n",
    "        rows = 1\n",
    "        cols = num_cols\n",
    "    else:\n",
    "        rows = math.ceil(num_cols/3)\n",
    "        cols = 3\n",
    "\n",
    "    # create a figure and a grid of subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(16, 4*rows))\n",
    "\n",
    "    sub_rows = 0\n",
    "    sub_cols = 0 \n",
    "    \n",
    "    # Make a bar plot.\n",
    "    if bar:\n",
    "        for f in bar:\n",
    "            # the number of the columns will be restricted to 3.\n",
    "            if sub_cols > cols-1:\n",
    "                sub_cols = 0\n",
    "                sub_rows += 1\n",
    "                \n",
    "            df_bar = df[f].value_counts()\n",
    "            # the x coordinates of the bars\n",
    "            x = [str(i) for i in df_bar.index]\n",
    "            # the heights of the bars\n",
    "            y = list(df_bar.values)\n",
    "            \n",
    "            # a feature is encoded, get the original name of the items from the dictionary\n",
    "            if f in cols_encoded.keys():\n",
    "                x = []\n",
    "                for i in list(df_bar.index):\n",
    "                    item_name = list(cols_encoded[f][int(i)].values())[0]\n",
    "                    x.append(item_name)\n",
    "            try:\n",
    "                # if the number of the features is less than 3\n",
    "                axes[sub_cols].bar(x, y, color='firebrick')\n",
    "                axes[sub_cols].set_title(f)\n",
    "                axes[sub_cols].set_xticklabels(x)\n",
    "\n",
    "            except:\n",
    "                axes[sub_rows, sub_cols].bar(x, y, color='firebrick')\n",
    "                axes[sub_rows, sub_cols].set_title(f)\n",
    "                axes[sub_rows, sub_cols].set_xticklabels(x)\n",
    "\n",
    "            sub_cols += 1\n",
    "    \n",
    "    # Make a histogram plot.\n",
    "    if hist:\n",
    "        for f in hist:\n",
    "            if sub_cols > cols-1:\n",
    "                sub_cols = 0\n",
    "                sub_rows += 1\n",
    "            \n",
    "            sigma = df[f].dropna().std()\n",
    "            mu = df[f].dropna().mean()\n",
    "            num_bins = 20\n",
    "            x = mu + sigma * np.random.randn(1000)\n",
    "            try:\n",
    "                n, bins, patches = axes[sub_cols].hist(df[f], num_bins, density=True, color='green', \n",
    "                                                       stacked=True, alpha=0.75)\n",
    "                y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "                    np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "                axes[sub_cols].plot(bins, y, '--', color ='black')\n",
    "                axes[sub_cols].set_title(f)\n",
    "            except:\n",
    "                n, bins, patches = axes[sub_rows, sub_cols].hist(df[f], num_bins, density=True, stacked=True,\n",
    "                                                                 color='green', alpha=0.75)\n",
    "                y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *\n",
    "                    np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "                axes[sub_rows, sub_cols].plot(bins, y, '--', color ='black')\n",
    "                axes[sub_rows, sub_cols].set_title(f)\n",
    "            sub_cols += 1\n",
    "    \n",
    "    # Make a scatter plot.\n",
    "    if scatter:\n",
    "        for f in scatter:\n",
    "            if sub_cols > cols-1:\n",
    "                sub_cols = 0\n",
    "                sub_rows += 1\n",
    "            \n",
    "            x = list(df[f].index)\n",
    "            y = list(df[f].values)\n",
    "            try:\n",
    "                axes[sub_cols].scatter(x, y, color ='blue')\n",
    "                axes[sub_cols].set_title(f)\n",
    "            except:\n",
    "                axes[sub_rows, sub_cols].scatter(x, y, color ='blue')\n",
    "                axes[sub_rows, sub_cols].set_title(f)\n",
    "                \n",
    "            sub_cols += 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title', 'Ticket_type', 'Ticket_num_len']\n",
    "hist = ['Age', 'Fare']\n",
    "scatter = []\n",
    "subplot_graph(df, bar, hist, scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-fourth",
   "metadata": {},
   "source": [
    "<a id='32'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        3.2 Drop Features Using Pearson Correlation\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "0\tSex\t2\t[male, female]\n",
    "1\tPclass\t3\t[3, 1, 2]\n",
    "2\tEmbarked\t3\t[S, C, Q]\n",
    "3\tTitle\t3\t[Mr, Miss, Mrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_one_hot = pd.get_dummies(['Sex', 'Pclass', 'Embarked', 'Title'], drop_first=True)\n",
    "df_one_hot = pd.get_dummies(['Sex', 'Pclass', 'Embarked', 'Title'])\n",
    "df_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(hm, figsize=(16, 8)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    im = ax.imshow(hm, cmap='viridis', aspect='auto')\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(len(hm.columns)))\n",
    "    ax.set_yticks(np.arange(len(hm.columns)))\n",
    "    # ... and label them with the respective list entries\n",
    "    ax.set_xticklabels(hm.columns)\n",
    "    ax.set_yticklabels(hm.columns)\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    ax.spines[:].set_visible(False)\n",
    "    ax.set_xticks(np.arange(hm.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(hm.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(hm.columns)):\n",
    "        for j in range(len(hm.columns)):\n",
    "            hm_val = round(hm.values[i, j], 2)\n",
    "            if hm_val > 0.85:\n",
    "                text = ax.text(j, i, hm_val,\n",
    "                               ha=\"center\", va=\"center\", color=\"black\", size=16)\n",
    "            else:\n",
    "                text = ax.text(j, i, hm_val,\n",
    "                               ha=\"center\", va=\"center\", color=\"w\", size=16)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select highly correlated features\n",
    "hm_X_train = df_one_hot.corr()\n",
    "create_heatmap(hm_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to select highly correlated features\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_features = correlation(df_one_hot, 0.75)\n",
    "corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot = df_one_hot.drop('Embarked_0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = [i for i in df.columns if i not in cat_cols]\n",
    "print(num_col)\n",
    "\n",
    "df = pd.concat([df[num_col], df_one_hot], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-running",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "   <h2>\n",
    "    4. Regressions and Results\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='PassengerId')\n",
    "X = df[df['PassengerId'] < 892]\n",
    "X = X.drop('PassengerId', axis=1)\n",
    "\n",
    "X_kaggle = df[df['PassengerId'] >= 892]\n",
    "X_kaggle = X_kaggle.drop('PassengerId', axis=1)\n",
    "\n",
    "print(X.shape)\n",
    "print(X_kaggle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-juvenile",
   "metadata": {},
   "source": [
    "<a id='42'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        4.2 Separate the dataset into train and test\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"Age\"]=np.log(X[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-ranch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-wisconsin",
   "metadata": {},
   "source": [
    "<a id='42'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        4.2 Check categorical columns\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no categorical columns in the dataframe\n",
    "categorical_feature_columns = list(set(df.columns) - set(df._get_numeric_data().columns))\n",
    "categorical_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feature_columns = list(df._get_numeric_data().columns)\n",
    "print(numerical_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-jefferson",
   "metadata": {},
   "source": [
    "<a id='43'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        4.3 Check zero variance features\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "### It will zero variance features\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thres=VarianceThreshold(threshold=0)\n",
    "var_thres.fit(df)\n",
    "df.columns[var_thres.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_columns = [column for column in df.columns\n",
    "                    if column not in df.columns[var_thres.get_support()]]\n",
    "\n",
    "print(len(constant_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-spiritual",
   "metadata": {},
   "source": [
    "<a id='45'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        4.5 Running Machine Learning Models\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    # Return the ccuracy classification score\n",
    "\n",
    "    # We will run the model with 10 different sets and we will get 10 results\n",
    "    cv = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "    # Applying Cross Validation to solve possible overfitting problem\n",
    "    scores_train = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "    acc_train = scores_train.mean()\n",
    "    scores_test = cross_val_score(model, X_test, y_test, scoring='accuracy', cv=cv)\n",
    "    acc_test = scores_test.mean()\n",
    "\n",
    "#     print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_train))\n",
    "#     print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_test))\n",
    "    \n",
    "    return acc_train, acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-partner",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.5.1 Logistic\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-eleven",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# log = LogisticRegression()\n",
    "# acc_log, acc_log_test = evaluate_model(log, X_train, X_test, y_train, y_test)\n",
    "# print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_log))\n",
    "# print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_log_test))\n",
    "# # df_cm_metrics = confusion_matrix_func(log, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression(C=8)\n",
    "\n",
    "params = {\n",
    "#     'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "#     'C': [i for i in np.arange(0, 10, 1)]\n",
    "#     'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "#     'max_iter': [50, 75, 100, 150, 200],\n",
    "#     'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "         }\n",
    "\n",
    "clf_log = GridSearchCV(estimator=log, cv=10, scoring='accuracy', param_grid=params).fit(X_train, y_train)\n",
    "# print('best prarams:', clf_log.best_params_)\n",
    "\n",
    "acc_log = clf_log.best_score_\n",
    "acc_log_test = clf_log.score(X_test, y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_log))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_log_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-batman",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.5.2 Random Forest\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-findings",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=randomforestclassifier#sklearn.ensemble.RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rf = RandomForestClassifier(max_depth=10,min_samples_split=9)\n",
    "# acc_rf, acc_rf_test = evaluate_model(rf, X_train, X_test, y_train, y_test)\n",
    "# print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_rf))\n",
    "# print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_rf_test))\n",
    "# # df_cm_metrics = confusion_matrix_func(rf, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=10, min_samples_split=10, min_samples_leaf=5)\n",
    "\n",
    "params = {\n",
    "#     'n_estimators': [50, 100, 125, 150, 200],\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [5, 10, 15, 20, 25, 30],\n",
    "#     'min_samples_split': [5, 10, 15, 20, 25, 30],\n",
    "#     'min_samples_leaf': [1, 3, 5, 10, 15, 20, 25, 30],\n",
    "         }\n",
    "\n",
    "clf_rf = GridSearchCV(estimator=rf, cv=10, scoring='accuracy', param_grid=params).fit(X_train, y_train)\n",
    "print('best prarams:', clf_rf.best_params_)\n",
    "\n",
    "acc_rf = clf_rf.best_score_\n",
    "acc_rf_test = clf_rf.score(X_test, y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_rf))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_rf_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-turkish",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.5.3 Naive Bayes\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-knitting",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html?highlight=bernoullinb#sklearn.naive_bayes.BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bNB = BernoulliNB()\n",
    "acc_bNB, acc_bNB_test = evaluate_model(bNB, X_train, X_test, y_train, y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_bNB))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_bNB_test))\n",
    "# df_cm_metrics = confusion_matrix_func(bNB, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bNB = BernoulliNB(alpha=2.0)\n",
    "\n",
    "params = {\n",
    "#     'alpha': [0.5, 1.0, 1.5, 2.0, 2.5],\n",
    "#     'binarize': [0.0, 0.5, 1.0, 1.5, 2.0, 2.5],\n",
    "#     'fit_prior': [False, True],\n",
    "#     'min_samples_split': [5, 10, 15, 20, 25, 30],\n",
    "#     'min_samples_leaf': [1, 3, 5, 10, 15, 20, 25, 30],\n",
    "         }\n",
    "\n",
    "clf_bNB = GridSearchCV(estimator=bNB, cv=10, scoring='accuracy', param_grid=params).fit(X_train, y_train)\n",
    "print('best prarams:', clf_bNB.best_params_)\n",
    "\n",
    "acc_bNB = clf_bNB.best_score_\n",
    "acc_bNB_test = clf_bNB.score(X_test, y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_bNB))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_bNB_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-sequence",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.5.4 SVM\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-mathematics",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html?highlight=svc#sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "acc_svm, acc_svm_test = evaluate_model(svm, X_train, X_test, y_train, y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_svm))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_svm_test))\n",
    "# df_cm_metrics = confusion_matrix_func(svm, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(C=0.1, kernel='linear')\n",
    "\n",
    "params = {\n",
    "#     'C': [0.1, 0.3, 0.5, 1.0, 1.5, 2.0, 2.5],\n",
    "#     'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#     'degree': [0.1, 0.5, 1, 2, 3, 4, 5, 6],\n",
    "         }\n",
    "\n",
    "clf_svm = GridSearchCV(estimator=svm, cv=10, scoring='accuracy', param_grid=params).fit(X_train, y_train)\n",
    "print('best prarams:', clf_svm.best_params_)\n",
    "\n",
    "acc_svm = clf_svm.best_score_\n",
    "acc_svm_test = clf_svm.score(X_test, y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_svm))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_svm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-qualification",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.5.5 k-Nearest Neighbours\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-bishop",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html?highlight=kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "acc_list = []\n",
    "acc_test_list = []\n",
    "for k in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    acc_knn, acc_knn_test = evaluate_model(knn, X_train, X_test, y_train, y_test)\n",
    "    acc_list.append(acc_knn)\n",
    "    acc_test_list.append(acc_knn_test)\n",
    "    \n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(range(1,40),acc_list,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.plot(range(1,40),acc_test_list,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='green', markersize=10)\n",
    "plt.title('Accuracy vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_max_list = [i for i in acc_list]\n",
    "k_max = acc_list.index(max(k_max_list))+1\n",
    "print(k_max)\n",
    "\n",
    "k_test_max_list = [i for i in acc_test_list]\n",
    "k_test_max = acc_test_list.index(max(k_test_max_list))+1\n",
    "print(k_test_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNeighborsClassifier(n_neighbors=k_test_max)\n",
    "# # knn = KNeighborsClassifier()\n",
    "# acc_knn, acc_knn_test = evaluate_model(knn, X_train, X_test, y_train, y_test)\n",
    "# print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_knn))\n",
    "# print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_knn_test))\n",
    "# # df_cm_metrics = confusion_matrix_func(knn, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k_test_max, weights='distance', p=1)\n",
    "\n",
    "params = {\n",
    "#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#     'leaf_size': [5, 10, 15, 20, 25, 30, 35],\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     'p': [1, 2, 3, 4, 5, 6],\n",
    "         }\n",
    "\n",
    "clf_knn = GridSearchCV(estimator=knn, cv=10, scoring='accuracy', param_grid=params).fit(X_train, y_train)\n",
    "print('best prarams:', clf_knn.best_params_)\n",
    "\n",
    "acc_knn = clf_knn.best_score_\n",
    "acc_knn_test = clf_knn.score(X_test, y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_knn))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_knn_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-hunter",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.5.6 Stochastic Gradient Descent\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-location",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html?highlight=sgdclassifier#sklearn.linear_model.SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# sgdc = SGDClassifier()\n",
    "# acc_sgdc, acc_sgdc_test = evaluate_model(sgdc, X_train, X_test, y_train, y_test)\n",
    "# print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_sgdc))\n",
    "# print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_sgdc_test))\n",
    "# # df_cm_metrics = confusion_matrix_func(sgdc, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgdc = SGDClassifier(loss='log', penalty='l1', alpha=0.0005, learning_rate='adaptive', \n",
    "                     eta0=0.01, power_t=0.03, validation_fraction=0.05, n_iter_no_change=9)\n",
    "\n",
    "params = {\n",
    "#     'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', \n",
    "#              'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "#     'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "#     'alpha': [i for i in np.arange(0.0001, 0.001, 1/10000)],\n",
    "#     'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "#     'eta0': [0.01, 0.03, 0.05, 0.07],\n",
    "#     'power_t': [0.01, 0.03, 0.05, 0.07, 0.1, 0.2, 0.3],\n",
    "#     'validation_fraction': [0.01, 0.03, 0.05, 0.07, 0.1, 0.2],\n",
    "#     'n_iter_no_change': [1, 3, 5, 7, 9, 11],\n",
    "         }\n",
    "\n",
    "clf_sgdc = GridSearchCV(estimator=sgdc, cv=10, scoring='accuracy', param_grid=params).fit(X_train, y_train)\n",
    "print('best prarams:', clf_sgdc.best_params_)\n",
    "\n",
    "acc_sgdc = clf_sgdc.best_score_\n",
    "acc_sgdc_test = clf_sgdc.score(X_test, y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_sgdc))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_sgdc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-laptop",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.5.7 Gradient Boosting Trees\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# gbc = GradientBoostingClassifier()\n",
    "# acc_gbc, acc_gbc_test = evaluate_model(gbc, X_train, X_test, y_train, y_test)\n",
    "# print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_gbc))\n",
    "# print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_gbc_test))\n",
    "# # df_cm_metrics = confusion_matrix_func(gbc, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(loss='exponential', learning_rate=0.3)\n",
    "\n",
    "params = {\n",
    "#         'loss': ['deviance', 'exponential'],\n",
    "#     'learning_rate': [0.05, 0.1, 0.2, 0.25, 0.3, 0.35],\n",
    "#     'n_estimators': [20,40,80,100,120],\n",
    "#     'subsample':[0.9,0.95,1,1.1],\n",
    "#     'criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "#     'max_depth': [1,2,3,4,6,8],\n",
    "    \n",
    "    \n",
    "#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#     'leaf_size': [5, 10, 15, 20, 25, 30, 35],\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     'p': [1, 2, 3, 4, 5, 6],\n",
    "         }\n",
    "\n",
    "clf_gbc = GridSearchCV(estimator=gbc, cv=10, scoring='accuracy', param_grid=params).fit(X_train, y_train)\n",
    "print('best prarams:', clf_gbc.best_params_)\n",
    "\n",
    "acc_gbc = clf_gbc.best_score_\n",
    "acc_gbc_test = clf_gbc.score(X_test, y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_gbc))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_gbc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-money",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.5.7 xgboost -> XGBClassifier\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-packaging",
   "metadata": {},
   "source": [
    "https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(booster='gbtree', eval_metric='logloss',eta=0.05, gamma=0, max_depth=10, \n",
    "                    min_child_weight=2.7, max_delta_step=2, subsample=1, colsample_bytree=1, alpha=0, \n",
    "                    tree_method='approx', sketch_eps=0.01, scale_pos_weight=1)\n",
    "\n",
    "# xgb = XGBClassifier(objective='binary:logistic')\n",
    "params = {\n",
    "#     'sketch_eps': [i for i in np.arange(0, 0.1, 1/100)],\n",
    "#     'eta': [0.01,0.03,0.05,0.07,0.09],\n",
    "#     'max_depth': [4,6,8,10,12],\n",
    "#     'n_estimators': [20,40,80,120],\n",
    "#     'min_child_weight' : [2.5,2.6,2.7,2.8,2.9,3],\n",
    "#     'max_delta_step':[1,1.5,2],\n",
    "#     'subsample':[0.9,0.95,1]\n",
    "         }\n",
    "\n",
    "clf_xgb = GridSearchCV(estimator=xgb, cv=5, scoring='accuracy', param_grid=params).fit(X_train, y_train)\n",
    "print('best prarams:', clf_xgb.best_params_)\n",
    "\n",
    "acc_xgb = clf_xgb.best_score_\n",
    "acc_xgb_test = clf_xgb.score(X_test, y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_xgb))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_xgb_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-syria",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.5.9 Model_Selection - Final\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GradientBoostingRegressor model with the highest R2 value has been selected.\n",
    "\n",
    "df_models_acc = pd.DataFrame({\n",
    "    'Model': ['log', 'rf', 'bNB', 'svm', 'knn', 'sgdc', 'gbc', 'xgb'],\n",
    "    'acc_Train': [acc_log, acc_rf, acc_bNB, acc_svm, acc_knn, acc_sgdc, acc_gbc, acc_xgb],\n",
    "    'acc_Test': [acc_log_test, acc_rf_test, acc_bNB_test, acc_svm_test, acc_knn_test, acc_sgdc_test, \n",
    "                 acc_gbc_test, acc_xgb_test],\n",
    "})\n",
    "df_models_acc.sort_values(by='acc_Test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-anxiety",
   "metadata": {},
   "source": [
    "<a id='44'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        4.4 Feature Selection\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(model):\n",
    "    model.fit_transform(X_train, y_train)\n",
    "    model_cols = X_train.columns[model.get_support()]\n",
    "\n",
    "    model_df = pd.DataFrame({'Feature':list(X_train.columns),\n",
    "                                         'Scores':model.scores_})\n",
    "    model_df = model_df.sort_values(by='Scores', ascending=False).reset_index(drop=True)\n",
    "    model_df.set_index('Feature', inplace=True)\n",
    "    ind_model = model_df.tail(10).index.to_list()\n",
    "    \n",
    "    return ind_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-broadcasting",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.4.2 GenericUnivariateSelect\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-calculation",
   "metadata": {},
   "source": [
    "Univariate feature selector with configurable strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-closure",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "# ANOVA F-value between label/feature for classification tasks.\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# mode{‚Äòpercentile‚Äô, ‚Äòk_best‚Äô, ‚Äòfpr‚Äô, ‚Äòfdr‚Äô, ‚Äòfwe‚Äô}, default=‚Äôpercentile‚Äô\n",
    "GUS_f = GenericUnivariateSelect(f_classif, mode='k_best', param=15)\n",
    "ind_GUS_f = feature_selection(GUS_f)\n",
    "print(ind_GUS_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-change",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "# Mutual information for a discrete target.\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "GUS_m = GenericUnivariateSelect(mutual_info_classif, mode='k_best', param=15)\n",
    "ind_GUS_m = feature_selection(GUS_m)\n",
    "print(ind_GUS_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-summer",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.4.1 SelectKBest\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-provision",
   "metadata": {},
   "source": [
    "Select features according to the k highest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-cattle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "# ANOVA F-value between label/feature for classification tasks.\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# select the  top k important features\n",
    "KBest_f = SelectKBest(f_classif, k=10)\n",
    "ind_KBest_f = feature_selection(KBest_f)\n",
    "print(ind_KBest_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-parcel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "# Mutual information for a discrete target.\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# select the  top k important features\n",
    "KBest_m = SelectKBest(mutual_info_classif, k=10)\n",
    "ind_KBest_m = feature_selection(KBest_m)\n",
    "print(ind_KBest_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-transition",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.4.1 SelectFpr\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-acrobat",
   "metadata": {},
   "source": [
    "Filter: Select the pvalues below alpha based on a FPR test.<br>\n",
    "FPR test stands for False Positive Rate test. It controls the total amount of false detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-philippines",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFpr\n",
    "# ANOVA F-value between label/feature for classification tasks.\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# select the  top k important features\n",
    "Fpr_f = SelectFpr(f_classif, alpha=0.01)\n",
    "ind_Fpr_f = feature_selection(Fpr_f)\n",
    "print(ind_Fpr_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-leave",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFpr\n",
    "# Mutual information for a discrete target.\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# select the  top k important features\n",
    "Fpr_m = SelectKBest(mutual_info_classif, k=10)\n",
    "ind_Fpr_m = feature_selection(Fpr_m)\n",
    "print(ind_Fpr_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-ultimate",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.4.1 SelectFdr\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-oxide",
   "metadata": {},
   "source": [
    "Filter: Select the p-values for an estimated false discovery rate<br>\n",
    "This uses the Benjamini-Hochberg procedure. alpha is an upper bound on the expected false discovery rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-benchmark",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFdr\n",
    "# ANOVA F-value between label/feature for classification tasks.\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# select the  top k important features\n",
    "Fdr_f = SelectFdr(f_classif, alpha=0.01)\n",
    "ind_Fdr_f = feature_selection(Fdr_f)\n",
    "print(ind_Fdr_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-danger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFdr\n",
    "# Mutual information for a discrete target.\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# select the  top k important features\n",
    "Fdr_m = SelectKBest(mutual_info_classif, k=10)\n",
    "ind_Fdr_m = feature_selection(Fdr_m)\n",
    "print(ind_Fdr_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-elder",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.4.3 RFE\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-foundation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "rfe = RFE(estimator=GradientBoostingClassifier(), step=1, n_features_to_select=10)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "rfe_cols = X_train.columns[rfe.get_support()]\n",
    "# print(rfe_cols)\n",
    "\n",
    "rfe_df = pd.DataFrame({'Feature':list(X_train.columns), 'Scores':rfe.ranking_})\n",
    "rfe_df.set_index('Feature', inplace=True)\n",
    "rfe_df = rfe_df.sort_values(by='Scores', ascending=True)\n",
    "ind_rfe = rfe_df.tail(10).index.to_list()\n",
    "print(ind_rfe)\n",
    "# rfe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-conference",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.4.4 RFECV\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "rfecv = RFECV(estimator=GradientBoostingClassifier(), step=1, cv=5, scoring='accuracy')\n",
    "rfecv = rfecv.fit(X_train, y_train)\n",
    "rfecv_cols = X_test.columns[rfecv.get_support()]\n",
    "\n",
    "rfecv_df = pd.DataFrame({'Feature':list(X_train.columns), 'Scores':rfecv.ranking_})\n",
    "rfecv_df.set_index('Feature', inplace=True)\n",
    "rfecv_df = rfecv_df.sort_values(by='Scores', ascending=True)\n",
    "ind_rfecv = rfecv_df.tail(10).index.to_list()\n",
    "print(ind_rfecv)\n",
    "# rfecv_df\n",
    "\n",
    "# print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
    "# print('Selected features: %s' % list(X_test.columns[rfecv.support_]))\n",
    "\n",
    "# # Plot number of features VS. cross-validation scores\n",
    "# plt.figure(figsize=(10,6))\n",
    "# plt.xlabel(\"Number of features selected\")\n",
    "# plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "# plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-chester",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.4.4 Recalculate Model\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-replication",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "new_cols_1 = (ind_GUS_f + ind_GUS_m + ind_KBest_f + ind_KBest_m + ind_Fpr_f + ind_Fpr_m+ind_Fdr_f + \n",
    "              ind_Fdr_m + ind_rfe + ind_rfecv)\n",
    "c = Counter(new_cols_1)\n",
    "df_counter = pd.DataFrame.from_records(list(dict(c).items()), columns=['feature','count'])\n",
    "df_counter = df_counter.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "df_counter.set_index('feature', inplace=True)\n",
    "# ind_counter = df_counter.head(6).index.to_list()\n",
    "# print(ind_counter)\n",
    "\n",
    "df_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-debut",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select columns\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "acc_xgb = 0.855480\n",
    "acc_xgb_test = 0.792793\n",
    "\n",
    "for num in range(1,15):\n",
    "    ind_counter = df_counter.head(num).index.to_list()\n",
    "    sel_cols = [i for i in X_train.columns if i not in ind_counter]\n",
    "    \n",
    "    xgb = XGBClassifier(booster='gbtree', eval_metric='logloss',eta=0.05, gamma=0, max_depth=10, \n",
    "                        min_child_weight=2.7, max_delta_step=2, subsample=1, colsample_bytree=1, alpha=0, \n",
    "                        tree_method='approx', sketch_eps=0.01, scale_pos_weight=1)\n",
    "\n",
    "    clf_xgb_sel = GridSearchCV(estimator=xgb, cv=5, scoring='accuracy', param_grid={}).fit(X_train[sel_cols], y_train)\n",
    "    acc_xgb_sel = clf_xgb_sel.best_score_\n",
    "    acc_xgb_sel_test = clf_xgb_sel.score(X_test[sel_cols], y_test)\n",
    "    \n",
    "    if (acc_xgb_sel_test >= acc_xgb_test):\n",
    "        acc_xgb = acc_xgb_sel\n",
    "        acc_xgb_test_sel = acc_xgb_test\n",
    "        print(sel_cols)\n",
    "        print(acc_xgb, acc_xgb_test_sel)\n",
    "        print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_xgb_sel))\n",
    "        print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_xgb_sel_test))\n",
    "        break\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run again\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "new_cols_xgb = ['Age', 'Fare', 'Pclass_2', 'Pclass_3', 'SibSp_1', 'SibSp_2', 'SibSp_3', 'SibSp_4', \n",
    "                'SibSp_8', 'Parch_1', 'Embarked_1', 'Embarked_2', 'Title_1', 'Title_2']\n",
    "\n",
    "xgb = XGBClassifier(booster='gbtree', eval_metric='logloss',eta=0.05, gamma=0, max_depth=10, \n",
    "                    min_child_weight=2.7, max_delta_step=2, subsample=1, colsample_bytree=1, alpha=0, \n",
    "                    tree_method='approx', sketch_eps=0.01, scale_pos_weight=1)\n",
    "\n",
    "clf_xgb_sel = GridSearchCV(estimator=xgb, cv=5, scoring='accuracy', param_grid={}).fit(X_train[new_cols_xgb], y_train)\n",
    "#     print('best prarams:', clf_xgb_sel.best_params_)\n",
    "\n",
    "acc_xgb_sel = clf_xgb_sel.best_score_\n",
    "acc_xgb_sel_test = clf_xgb_sel.score(X_test[new_cols_xgb], y_test)\n",
    "print(sel_cols)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_xgb_sel))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_xgb_sel_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-shannon",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.4.3 SelectFromModel\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-uruguay",
   "metadata": {},
   "source": [
    "Meta-transformer for selecting features based on importance weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-software",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we want to select the two features which are the most important.\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "xgb = XGBClassifier(booster='gbtree', eval_metric='logloss',eta=0.05, gamma=0, max_depth=10, \n",
    "                    min_child_weight=2.7, max_delta_step=2, subsample=1, colsample_bytree=1, alpha=0, \n",
    "                    tree_method='approx', sketch_eps=0.01, scale_pos_weight=1)\n",
    "\n",
    "clf_xgb_sel = GridSearchCV(estimator=xgb, cv=5, scoring='accuracy', param_grid={}).fit(X_train, y_train)\n",
    "thresholds = np.sort(clf_xgb_sel.best_estimator_.feature_importances_)\n",
    "print(thresholds)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    print(thresh)\n",
    "    clf_xgb_sel_best=clf_xgb_sel.best_estimator_.fit(X_train,y_train)\n",
    "    SFM = SelectFromModel(clf_xgb_sel_best, threshold=thresh).fit(X_train, y_train)\n",
    "    SFM.get_support()\n",
    "    ind_SFM = X_train.columns[SFM.get_support()]\n",
    "    \n",
    "    clf_xgb_sel = GridSearchCV(estimator=xgb, cv=5, scoring='accuracy', param_grid={}).fit(X_train[ind_SFM], y_train)\n",
    "\n",
    "    acc_xgb_sel = clf_xgb_sel.best_score_\n",
    "    acc_xgb_sel_test = clf_xgb_sel.score(X_test[ind_SFM], y_test)\n",
    "    print(ind_SFM)\n",
    "    print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_xgb_sel))\n",
    "    print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_xgb_sel_test))\n",
    "    print('=======')\n",
    "\n",
    "\n",
    "#     print(ind_SFM)\n",
    "    # SFM.threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "SFM = SelectFromModel(clf_xgb_sel_best, threshold=0.023025082).fit(X_train, y_train)\n",
    "SFM.get_support()\n",
    "new_cols_SFM = X_train.columns[SFM.get_support()]\n",
    "print(new_cols_SFM)\n",
    "\n",
    "clf_xgb_sel = GridSearchCV(estimator=xgb, cv=5, scoring='accuracy', param_grid={}).fit(X_train[new_cols_SFM], y_train)\n",
    "acc_xgb_sel = clf_xgb_sel.best_score_\n",
    "acc_xgb_sel_test = clf_xgb_sel.score(X_test[ind_SFM], y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_xgb_sel))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_xgb_sel_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-facial",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.4.3 SequentialFeatureSelector\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "xgb = XGBClassifier(booster='gbtree', eval_metric='logloss',eta=0.05, gamma=0, max_depth=10, \n",
    "                    min_child_weight=2.7, max_delta_step=2, subsample=1, colsample_bytree=1, alpha=0, \n",
    "                    tree_method='approx', sketch_eps=0.01, scale_pos_weight=1)\n",
    "\n",
    "sfs_forward = SequentialFeatureSelector(xgb, n_features_to_select=13,\n",
    "                                        direction='forward').fit(X_train, y_train)\n",
    "\n",
    "sfs_backward = SequentialFeatureSelector(xgb, n_features_to_select=13,\n",
    "                                         direction='backward').fit(X_train, y_train)\n",
    "\n",
    "print(\"Features selected by forward sequential selection: \"\n",
    "      f\"{X_train.columns[sfs_forward.get_support()]}\")\n",
    "print(\"Features selected by backward sequential selection: \"\n",
    "      f\"{X_train.columns[sfs_backward.get_support()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols_forw = ['Age', 'Fare', 'Pclass_2', 'Pclass_3', 'SibSp_1', 'SibSp_2', 'SibSp_3',\n",
    "       'SibSp_4', 'SibSp_5', 'SibSp_8', 'Embarked_2', 'Title_1', 'Title_2']\n",
    "new_cols_back = ['Age', 'Fare', 'Pclass_2', 'Pclass_3', 'SibSp_1', 'Parch_1', 'Parch_2',\n",
    "       'Parch_6', 'Parch_9', 'Embarked_1', 'Embarked_2', 'Title_1', 'Title_2']\n",
    "\n",
    "new_cols_sfs = [i for i in new_cols_back if i in new_cols_forw]\n",
    "clf_xgb_sel = GridSearchCV(estimator=xgb, cv=5, scoring='accuracy', param_grid={}).fit(X_train[new_cols_sfs], y_train)\n",
    "acc_xgb_sel = clf_xgb_sel.best_score_\n",
    "acc_xgb_sel_test = clf_xgb_sel.score(X_test[new_cols_sfs], y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_xgb_sel))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_xgb_sel_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-denver",
   "metadata": {},
   "source": [
    "<a id='46'></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h3>\n",
    "        4.6 Evaluating the Model\n",
    "   </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-perspective",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.6.1 Confusion matrix\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols_xgb\n",
    "new_cols_SFM\n",
    "new_cols_sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = new_cols_SFM\n",
    "xgb = XGBClassifier(booster='gbtree', eval_metric='logloss',eta=0.05, gamma=0, max_depth=10, \n",
    "                    min_child_weight=2.7, max_delta_step=2, subsample=1, colsample_bytree=1, alpha=0, \n",
    "                    tree_method='approx', sketch_eps=0.01, scale_pos_weight=1)\n",
    "\n",
    "model = GridSearchCV(estimator=xgb, cv=5, scoring='accuracy', param_grid={}).fit(X_train[new_cols], y_train)\n",
    "\n",
    "acc_xgb_sel = model.best_score_\n",
    "acc_xgb_sel_test = model.score(X_test[new_cols], y_test)\n",
    "print('The Accuracy  on the training dataset is: {:.1%}'.format(acc_xgb_sel))\n",
    "print('The Accuracy  on the testing dataset is: {:.1%}'.format(acc_xgb_sel_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confusion_matrix_metrics(TP, FP, FN, TN):\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP / (TP + FN)\n",
    "#     print('The True Positive Rate is: {:.2%}'.format(TPR))\n",
    "    # Specificity, selectivity or true negative rate (TNR)\n",
    "    TNR = TN / (TN + FP)\n",
    "#     print('The True Negative Rate is: {:.2%}'.format(TNR))\n",
    "#     print('='*10)\n",
    "\n",
    "    # accuracy (ACC)\n",
    "    ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "#     print('The Accuracy is: {:.2%}'.format(ACC))\n",
    "    # balanced accuracy (BA)\n",
    "    BA = (TPR + TNR) / 2\n",
    "#     print('The Balanced Accuracy is: {:.2%}'.format(BA))\n",
    "#     print('='*10)\n",
    "\n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP / (TP + FP)\n",
    "#     print('The Precision is: {:.2%}'.format(PPV))\n",
    "    # negative predictive value (NPV)\n",
    "    NPV = TN / (TN + FN)\n",
    "#     print('The Negative Predictive Value is: {:.2%}'.format(NPV))\n",
    "    # false discovery rate (FDR)\n",
    "    FDR = 1 - PPV\n",
    "#     print('The False Discovery Rate is: {:.2%}'.format(FDR))\n",
    "    # false omission rate (FOR)\n",
    "    FOR = 1 - NPV\n",
    "#     print('The False Omission Rate is: {:.2%}'.format(FOR))\n",
    "#     print('='*10)\n",
    "\n",
    "    # prevalence threshold (PT)\n",
    "    PT = (math.sqrt(TPR*(1 - TNR)) + TNR - 1)/(TPR + TNR - 1)\n",
    "#     print('The Prevalence Threshold is: {:.2}'.format(PT))\n",
    "    # F1 score\n",
    "    F1 = 2*TP / (2*TP + FP + FN)\n",
    "#     print('The F1 Score is: {:.2}'.format(F1))\n",
    "    # Matthews correlation coefficient (MCC) or phi coefficient\n",
    "    MCC = ((TP*TN) - (FP*FN)) / math.sqrt((TP + FP)*(TP + FN)*(TN + FP)*(TN + FN))\n",
    "#     print('The Matthews Correlation Coefficient is: {:.2}'.format(MCC))\n",
    "#     print('='*10)\n",
    "\n",
    "    # False positive rate or False alarm rate\n",
    "    FPR = FP / (FP + TN)\n",
    "#     print('The False positive rate is: {:.2}'.format(FPR))\n",
    "    # False negative rate or Miss Rate\n",
    "    FNR = FN / (FN + TP)\n",
    "#     print('The False Negative Rate is: {:.2%}'.format(FNR))\n",
    "    \n",
    "    return TPR, TNR, ACC, BA, PPV, NPV, FDR, FOR, PT, F1, MCC, FPR, FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_func(model, X_train, X_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    cm = confusion_matrix(y_train, y_pred).T\n",
    "    cm_test = confusion_matrix(y_test, y_pred_test).T\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = axes[0].imshow(cm, interpolation='nearest', cmap='Reds', aspect='auto')\n",
    "    # show all ticks\n",
    "    axes[0].set_xticks(np.arange(len(cm.tolist())))\n",
    "    axes[0].set_yticks(np.arange(len(cm.tolist())))\n",
    "    thresh = cm.max() / 1.5\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(cm.tolist())):\n",
    "        for j in range(len(cm.tolist())):\n",
    "            text = axes[0].text(j, i, cm.tolist()[i][j],\n",
    "                           ha=\"center\", va=\"center\", size=16,\n",
    "                           color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    axes[0].xaxis.set_ticks_position('top')\n",
    "    axes[0].xaxis.set_label_position('top')\n",
    "    axes[0].set_xlabel('Actual value', size=16)\n",
    "    axes[0].set_ylabel('Predicted value', size=16)\n",
    "    axes[0].set_title(\"Train\", fontsize=20)\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    im = axes[1].imshow(cm_test, interpolation='nearest', cmap='Reds', aspect='auto')\n",
    "    # show all ticks\n",
    "    axes[1].set_xticks(np.arange(len(cm_test.tolist())))\n",
    "    axes[1].set_yticks(np.arange(len(cm_test.tolist())))\n",
    "    thresh = cm_test.max() / 1.5\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(cm_test.tolist())):\n",
    "        for j in range(len(cm_test.tolist())):\n",
    "            text = axes[1].text(j, i, cm_test.tolist()[i][j],\n",
    "                           ha=\"center\", va=\"center\", size=16,\n",
    "                           color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    axes[1].xaxis.set_ticks_position('top')\n",
    "    axes[1].xaxis.set_label_position('top')\n",
    "    axes[1].set_xlabel('Actual value', size=16)\n",
    "    axes[1].set_title(\"Test\", fontsize=20)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "    \n",
    "    # Calculating False Positives (FP), False Negatives (FN), True Positives (TP) & True Negatives (TN)\n",
    "    TP, FP, FN, TN = cm.ravel()\n",
    "    TPR, TNR, ACC, BA, PPV, NPV, FDR, FOR, PT, F1, MCC, FPR, FNR = Confusion_matrix_metrics(TP, FP, FN, TN)\n",
    "    TP_test, FP_test, FN_test, TN_test = cm_test.ravel()\n",
    "    (TPR_test, TNR_test, ACC_test, BA_test, PPV_test, NPV_test, FDR_test, FOR_test, PT_test, F1_test, \n",
    "     MCC_test, FPR_test, FNR_test) = Confusion_matrix_metrics(TP_test, FP_test, FN_test, TN_test)\n",
    "    \n",
    "    df_cm_metrics = pd.DataFrame({\n",
    "    'Model': ['True Positive Rate', 'True Negative Rate', 'Accuracy', 'Balanced Accuracy', 'Precision', \n",
    "              'Negative Predictive Value', 'False Discovery Rate', 'False Omission Rate', \n",
    "              'Prevalence Threshold', 'F1 Score', 'Matthews Correlation Coefficient', \n",
    "              'False positive rate', 'False Negative Rate'],\n",
    "    'Train': [TPR, TNR, ACC, BA, PPV, NPV, FDR, FOR, PT, F1, MCC, FPR, FNR],\n",
    "    'Test': [TPR_test, TNR_test, ACC_test, BA_test, PPV_test, NPV_test, FDR_test, FOR_test, PT_test, F1_test, \n",
    "     MCC_test, FPR_test, FNR_test],\n",
    "    })\n",
    "    \n",
    "    return df_cm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-chamber",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cm_metrics = confusion_matrix_func(model, X_train[new_cols], X_test[new_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-regulation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cm_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-identity",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.6.2 roc curve and auc\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train[new_cols])\n",
    "y_pred_test = model.predict(X_test[new_cols])\n",
    "pred_proba_train = model.predict_proba(X_train[new_cols])\n",
    "pred_proba_test = model.predict_proba(X_test[new_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-spotlight",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "\n",
    "# TRAIN\n",
    "# calculate scores\n",
    "lr_auc = roc_auc_score(y_train, pred_proba_train[:, 1])\n",
    "# summarize scores\n",
    "# print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, thresholds = roc_curve(y_train, pred_proba_train[:, 1])\n",
    "\n",
    "# Evaluating model performance at various thresholds\n",
    "df_roc = pd.DataFrame({\n",
    "    'False Positive Rate': lr_fpr,\n",
    "    'True Positive Rate': lr_tpr\n",
    "}, index=thresholds)\n",
    "df_roc.index.name = \"Thresholds\"\n",
    "df_roc.columns.name = \"Rate\"\n",
    "\n",
    "\n",
    "# TEST\n",
    "# calculate scores\n",
    "lr_auc_test = roc_auc_score(y_test, pred_proba_test[:, 1])\n",
    "# summarize scores\n",
    "# print('Logistic: ROC AUC=%.3f' % (lr_auc_test))\n",
    "# calculate roc curves\n",
    "lr_fpr_test, lr_tpr_test, thresholds_test = roc_curve(y_test, pred_proba_test[:, 1])\n",
    "\n",
    "# Evaluating model performance at various thresholds\n",
    "df_roc_test = pd.DataFrame({\n",
    "    'False Positive Rate': lr_fpr_test,\n",
    "    'True Positive Rate': lr_tpr_test\n",
    "}, index=thresholds_test)\n",
    "df_roc_test.index.name = \"Thresholds\"\n",
    "df_roc_test.columns.name = \"Rate\"\n",
    "\n",
    "\n",
    "# GRAPH\n",
    "# Set up the matplotlib figure\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# row=0, col=0\n",
    "axes[0, 0].plot(df_roc.iloc[:,0], df_roc.iloc[:,1], color='red', linewidth=2, \n",
    "                label=f'AUC={lr_auc:.2f}')\n",
    "axes[0, 0].fill_between(df_roc.iloc[:,0], df_roc.iloc[:,1], 0, color='red', alpha=0.3)\n",
    "axes[0, 0].plot(df_roc_test.iloc[:,0], df_roc_test.iloc[:,1], color='black', linewidth=2, \n",
    "                label=f'AUC_test={lr_auc_test:.2f}')\n",
    "axes[0, 0].plot([0, 1], [0, 1], color='green', linestyle='--', linewidth=1,\n",
    "                label='No Skill')\n",
    "\n",
    "# index of the first threshold for which the sensibility > 0.90\n",
    "idx = np.min(np.where(lr_tpr > 0.90))\n",
    "axes[0, 0].plot([0,lr_fpr[idx]], [lr_tpr[idx],lr_tpr[idx]], 'k--', color='blue')\n",
    "axes[0, 0].plot([lr_fpr[idx],lr_fpr[idx]], [0,lr_tpr[idx]], 'k--', color='blue')\n",
    "# Annotation\n",
    "axes[0, 0].annotate('(%.2f, %.2f)'%(lr_fpr[idx], lr_tpr[idx]),\n",
    "            (lr_fpr[idx], lr_tpr[idx]), \n",
    "            xytext =(-2 * 50, -30),\n",
    "            textcoords ='offset points',\n",
    "            bbox = dict(boxstyle =\"round\", fc =\"0.8\"), \n",
    "            arrowprops = dict(arrowstyle = \"->\"))\n",
    "\n",
    "axes[0, 0].set_xlabel('False Positive Rate', size=12)\n",
    "axes[0, 0].set_ylabel('True Positive Rate (recall)', size=12)\n",
    "axes[0, 0].legend(title='kNN')\n",
    "axes[0, 0].set_title('ROC curve', color='red', size=14)\n",
    "\n",
    "# row=0, col=1\n",
    "axes[0, 1].plot(df_roc.index[1:], df_roc[\"True Positive Rate\"][1:], color='blue', linewidth=2, \n",
    "                label='TPR')\n",
    "axes[0, 1].plot(df_roc_test.index[1:], df_roc_test[\"True Positive Rate\"][1:], color='black', linewidth=2, \n",
    "                label='TPR_test')\n",
    "axes[0, 1].plot(df_roc.index[1:], df_roc[\"False Positive Rate\"][1:], color='orange', linewidth=2, \n",
    "                label='FPR')\n",
    "axes[0, 1].plot(df_roc_test.index[1:], df_roc_test[\"False Positive Rate\"][1:], color='black', linewidth=2, \n",
    "                label='FPR_test')\n",
    "\n",
    "axes[0, 1].set_xlabel('Threshold', size=12)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_title('TPR and FPR at every threshold', color='red', size=14)\n",
    "\n",
    "# row=1, col=0\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, pred_proba_test[:, 1])\n",
    "\n",
    "axes[1, 0].plot(recall, precision, color='green', linewidth=2, \n",
    "                label=f'PR_Curve (AUC={auc(lr_fpr, lr_tpr):.2f})')\n",
    "axes[1, 0].fill_between(recall, precision, 0, color='green', alpha=0.3)\n",
    "\n",
    "axes[1, 0].set_xlabel('Recall', size=12)\n",
    "axes[1, 0].set_ylabel('Precision', size=12)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_title('Precision-Recall Curve', color='red', size=14)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-exposure",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h4>\n",
    "        4.6.3 Logarithmic loss\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "# Running Log loss on training\n",
    "print('The Log Loss on Training is: {:.2}'.format(log_loss(y_train, pred_proba_train[:, 1])))\n",
    "\n",
    "# Running Log loss on testing\n",
    "print('The Log Loss on Testing Dataset is: {:.2}'.format(log_loss(y_test, pred_proba_test[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-marine",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <h2>\n",
    "        5. Submission\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle_final = X_kaggle[new_cols]\n",
    "X_kaggle_final[\"Age\"]=np.log(X_kaggle_final[\"Age\"])\n",
    "submission = gender_submission.drop('Survived', axis=1)\n",
    "y_pred_kaggle = model.predict(X_kaggle_final)\n",
    "submission['Survived'] = y_pred_kaggle\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are our test and submission dataframes the same length?\n",
    "if len(submission) == len(gender_submission):\n",
    "    print(\"Submission dataframe is the same length as test ({} rows).\".format(len(submission)))\n",
    "else:\n",
    "    print(\"Dataframes mismatched, won't be able to submit to Kaggle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert submisison dataframe to csv for submission to csv for Kaggle submisison\n",
    "submission.to_csv('titanic_submission_kaggle_11.csv', index=False)\n",
    "print('Submission CSV is ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the submission csv to make sure it's in the right format\n",
    "submissions_check = pd.read_csv(\"titanic_submission_kaggle_11.csv\")\n",
    "submissions_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-spouse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-formula",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-asbestos",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-press",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, cohen_kappa_score, roc_auc_score, f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# # Compute Cohen's Kappa or Auc as scoring criterion due to imbalanced data set\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "auc_scorer=make_scorer(roc_auc_score)\n",
    "F_measure_scorer = make_scorer(f1_score)\n",
    "\n",
    "##hyperparameter\n",
    "\n",
    "param_grid = {\n",
    "    'clf__colsample_bytree': [i/10.0 for i in range(7,10)],\n",
    "    #\"clf__subsample\"  : [i/10.0 for i in range(5,10)],\n",
    "    #'clf__max_depth':range(5,15,1),\n",
    "    #'clf__gamma':[i/10.0 for i in range(0,5)],\n",
    "    #'clf__reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "\n",
    "            }\n",
    "\n",
    "xg = XGBClassifier(booster='gbtree', eval_metric='logloss',eta=0.05, gamma=0, max_depth=10, \n",
    "                    min_child_weight=2.7, max_delta_step=2, subsample=1, colsample_bytree=1, alpha=0, \n",
    "                    tree_method='approx', sketch_eps=0.01, scale_pos_weight=1)\n",
    "\n",
    "# ##Classifier\n",
    "# xg=XGBClassifier(max_depth=3,\n",
    "#                  learning_rate=0.05,\n",
    "#                  n_estimators=350,\n",
    "#                  objective=\"binary:logistic\",\n",
    "#                  booster=\"gbtree\",\n",
    "#                  gamma=0,\n",
    "#                  min_child_weight=0.8,\n",
    "#                  subsample=1,\n",
    "#                  colsample_bylevel=1,\n",
    "#                  colsample_bytree=0.6,\n",
    "#                  reg_alpha=0.001,\n",
    "#                  reg_lambda=1,\n",
    "#                  scale_pos_weight=22,\n",
    "#                  random_state=4,n_jobs=-1)\n",
    "pipe=Pipeline(steps=[('pre',scaler),\n",
    "                    ('clf',xg)])\n",
    "\n",
    "rg_cv = GridSearchCV(pipe, param_grid, cv=5, scoring = 'f1')\n",
    "rg_cv.fit(X_train, y_train)\n",
    "print(\"Tuned rf best params: {}\".format(rg_cv.best_params_))\n",
    "\n",
    "# Use SelectFromModel\n",
    "thresholds = np.sort(rg_cv.best_estimator_.named_steps[\"clf\"].feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    print(\"Tuned rf best params: {}\".format(rg_cv.best_params_))\n",
    "    be=rg_cv.best_estimator_\n",
    "    best=be.fit(X_train,y_train)\n",
    "    thresholds = np.sort(rg_cv.best_estimator_.named_steps[\"clf\"].feature_importances_)\n",
    "    for thresh in thresholds:\n",
    "        # select features using threshold\n",
    "        selection = SelectFromModel(be.steps [1][1], threshold=thresh, prefit=True)\n",
    "    \n",
    "#     # select features using threshold\n",
    "#     selection = SelectFromModel(rg_cv, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "\n",
    "    # train model\n",
    "    selection_model = rg_cv\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy * 100.0))\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "#     print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
